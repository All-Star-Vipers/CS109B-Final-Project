{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "In order to feed the data into our CNN, we took 13,000 posters from the IMDB databases. Given how we downloaded our posters and the meta data from TMDB and IMDB. 70% of these posters were allocated into a training group, and the remaining 30% were allocated into the testing group.\n",
    "\n",
    "## Color\n",
    "\n",
    "Initially, in order to reduce the compute power needed and save the amount of space loaded into RAM, we only used greyscale images as image data fed into our CNN. However, we found that solely using greyscale images made it difficult for us as 'humans' to identify the genre of a movie by its poster alone. We found also found, that with a simple 2 layered CNN, we were only able to classify 10% of the images correctly. Given that at that time we were using 11 classes, this was only slighty higher than chance (9%).\n",
    "\n",
    "## Image Size\n",
    "Initally, we downloaded all of the images from TMBD with the size of 750 x 500 pixels. Given that we were loading thoasands of arrays of shape 750x500x3 we were unable to run our CNN at this size.  The higher ram cluster, would have cost us approximately $15/hour to process this level of photo. Ultimately, we changed the size to 150x500x3 (with last dimension being three separate arrays, each with of its own primary color.\n",
    "\n",
    "## Meta Data\n",
    "\n",
    "We also loaded in the meta data for each of the movies. Given that we were able to classify with approximately a 40 percent accuracy rate using XGBOOST and the relevant meta data for each movie, we thought it was likely that the meta data would include relevant factors about a genre that is not held in the movie's pixels.  In fact, we found that when we didn't utilize meta data in our analysis, our CNN solely selected the dominant class when classifying movie posters.\n",
    "\n",
    "## Pretuneing the models\n",
    "In addition to utilizing meta data, we pre-tuned our models with some existing keras packages and data.  When we pre-tuned our models, we had the same classification score and loss as when we did not pretune our models (34 percent).  This compared to a 46 percent classification score when we utilized our CNN with poster images in addition to meta data.\n",
    "\n",
    "\n",
    "## CNN Architecture\n",
    "Through testing the different levels of loss we saw when we changed the architecture of our CNN, we ultimately utilized a Neural Net with 10 hidden layers, interspersed with max pooling.  We then added our meta data and utilized additional hidden layers, and merged our poster and meta data layers together.  Finally, we utilized dropout on our merged nets to reduce overfitting of our training data.\n",
    "\n",
    "## Tuning the CNN\n",
    "#### Batch size\n",
    "Given that we only had approximately 10,000 posters to work with in our training set, we kept our batch size very small, at 10, with the idea of maximizing the number of opportunities for training the network in each epoch.  \n",
    "\n",
    "#### Learning Rate\n",
    "Initially, we had a very high learning rate of 0.5, but this resulted in a our network finding a local minimum immediately and not improving from epoch to epoch.\n",
    "At a learning rate of 0.001, our improvements in classification level off after around the 25th epoch, but we were able to reacha  much higher classificaiton score.\n",
    "\n",
    "## Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Screencast\n",
    "Our team wanted to determine if we could further improve our classification of movie genres from our SVM and XGBoost models using the feature film posters for each movie.\n",
    "\n",
    "Our methods were to first download all of the available movie posters for each of the films we analyzed in our SVM and XGBoost models.  While these posters were originally each made of three 750x500 matrixes, with each matrix holding relevant color pixel information, we compressed the posters to a 150x100x3 size, and maintained the color information.  This was performed to reduce the amount of compute power needed to process these images.  Next, we built a Convoluted Neural Net (CNN) with the following architecture.\n",
    "\n",
    "Through testing the different levels of loss we saw when we changed the architecture of our CNN, we ultimately utilized a Neural Net with 10 hidden layers, interspersed with max pooling.  We then added our meta data and utilized additional hidden layers, and merged our poster and meta data layers together.  Finally, we utilized dropout on our merged nets to reduce overfitting of our training data.\n",
    "\n",
    "Utilizing stoichastic gradient descent, a learning rate of 0.01, a batch size of 10, a maximum of 200 epochs, evaluating our model's loss with categorical cross entropy, and utilizing the meta-data from each poster that was utilized as features in the SVM and XGBoost models, we were able to reach a highest classification score of 46% on our poster testing set.  As we had 7 classes in our model, picking a genre at random would be approximately 14%.  Our final model was able to classify posters based on meta data and poster images at 3 times greater than chance.\n",
    "\n",
    "When we used pre-trained models, or models without the meta data, our CNN predicted all of our test set as the dominant class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
